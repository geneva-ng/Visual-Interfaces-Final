# Visual-Interfaces-Final

We developed a UNO Bot as an assisted gameplay system for our Visual Interfaces final project. The bot recognizes cards from live video feed, suggesting legal moves by deploying an object detection model. The project went through three phases: object detection model development, model deployment, and game logic implementation. 

The object detection dataset development process involved experimenting with various approaches such as annotation techniques, dataset size, class expansion, dataset preprocessing, and model types. Roboflow, a cloud-based platform, was used for dataset generation, which included uploading images, manual annotation with bounding boxes and class assignment, and splitting the dataset into training, validation, and test sets. We first attempted to train the model to recognize the entire UNO card face, but limitations were identified in terms of classifying numbers and actions and the lack of background variation. We then shifted to corner card recognition, annotating the top left and bottom right corners for number and color detection to work around this issue. A larger dataset was created by downloading raw images of various fans of UNO cards and augmenting the dataset using Roboflow’s data augmentation tools resulting in a final data set of 8.8k test images, 482 validation images, and 266 test images, which were used to train a YOLOv8 model.

The project utilized the YOLOv8 object detection algorithm for its accuracy and real-time capabilities in detecting and classifying objects. However, the slow training time posed a significant challenge, limiting the ability to fine-tune the model and experiment with different configurations. Google Colab Notebook was chosen for training due to its access to GPUs and collaborative environment.  Nine versions of the model were generated, progressively improving the mean Average Precision (mAP) from 43.6% to 92.6% by increasing the dataset size and manipulating underrepresented classes. Challenges included difficulty distinguishing between certain card numbers and colors, but overall, the final version performed well during independent testing.

The writeup provided includes provisional iterations of algorithms developed alongside the model's formulation. In the "Play to Play" approach, the system selects a playable card without considering external factors. The algorithm checks conditions such as color, number, and action to determine if a card can be played. If no viable cards are found, it returns None. Otherwise, it selects the first viable card as the chosen card. The "Play to Win" approach incorporates heuristics or probability insights to determine the optimal card to play. The algorithm prioritizes aggressive gameplay by focusing on disrupting the opponent's turn and controlling the game's flow. It selects cards based on heuristics such as same-color action cards, wildcards, same-color cards, and same-number cards. If no valid card is found, it chooses a wildcard. To evaluate the effectiveness of each algorithm, a simulation was conducted. The simulation involved players using one of the algorithms, playing multiple rounds, and tracking the number of wins. Though the heuristic and probability-based algorithms were valiant efforts at optimizing UNO gameplay, our simplistic "Play-to-Play" algorithm emerged as the clear winner, consistently outperforming the attempts at creating aggressive gameplay algorithms and achieving a higher win rate. Its balanced approach and focus on making optimal card plays based on the current game state proved to be more effective in securing victories during our testing and evaluation.

To seamlessly integrate our model into a live game of Uno, we used two cameras to capture the live deck and player's hand. Initially, we encountered difficulties with a single camera system, but the use of a Surface Book Pro, equipped with both a front and back camera, resolved the issue. We implemented the system by opening the cameras, capturing frames, applying predictions, and displaying them along with the suggested card written to the terminal. To improve performance, we separated the capture and prediction steps, resulting in better real-time performance and reduced computational load.

For a more in-depth exploration of our trials, errors, troubleshooting, and algorithm development, feel free to check out the writeup I’ve included. 
